{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda) # This should print the CUDA version PyTorch was built with (e.g., '11.8', '12.1'), NOT 'None'\n",
    "print(torch.backends.cudnn.is_available()) # Should also be True if CUDA is working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 785]), torch.Size([10000, 785]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from the csv file\n",
    "x_train = np.loadtxt('mnist_train.csv', delimiter=',') # x_train is (60000, 785), 785 bc of label at index 0\n",
    "x_test = np.loadtxt('mnist_test.csv', delimiter=',')\n",
    "\n",
    "# convert to torch tensors\n",
    "x_train = torch.from_numpy(x_train).to(torch.int16) # we only need int16 bc our values are nowhere near 2^16\n",
    "x_test = torch.from_numpy(x_test).to(torch.int16)\n",
    "\n",
    "encode = lambda x: (x + 10) # add 10 to every grayscale value to account for CLS tokens 0-9; now, gs values are 10-265.\n",
    "decode = lambda x: (x - 10)\n",
    "x_train[:, 1:] = encode(x_train[:, 1:]) # (60000, 785)\n",
    "x_test[:, 1:] = encode(x_test[:, 1:])   # (10000, 785)\n",
    "\n",
    "# split the training data into training and validation sets\n",
    "train_subset, val_subset = torch.utils.data.random_split(x_train, [50000, 10000])\n",
    "x_train_split = x_train[train_subset.indices] \n",
    "x_val = x_train[val_subset.indices]\n",
    "x_train = x_train_split\n",
    "x_train.shape, x_val.shape # (50000, 785) (10000, 785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When context is [3], the target is 10\n",
      "When context is [3, 10], the target is 10\n",
      "When context is [3, 10, 10], the target is 10\n",
      "When context is [3, 10, 10, 10], the target is 10\n",
      "When context is [3, 10, 10, 10, 10], the target is 10\n"
     ]
    }
   ],
   "source": [
    "# batching\n",
    "batch_size = 32\n",
    "seq_len = x_train.shape[1] - 1 # 784\n",
    "\n",
    "def get_batch(split):\n",
    "    data = x_train if split == 'train' else x_val\n",
    "    indices = torch.randint(len(data), (batch_size,)) # basically, get 32 photos\n",
    "    x = data[indices, :-1] # (batch_size, 784)\n",
    "    y = data[indices, 1:]  # (batch_size, 784)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "xb.shape, yb.shape # (32, 784) (32, 784)\n",
    "\n",
    "# peace of mind check\n",
    "for i in range(5):\n",
    "    context = xb[0, :i+1]\n",
    "    target = yb[0, i]\n",
    "    print(f\"When context is {context.tolist()}, the target is {target.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3076, 0.6924, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2689, 0.2543, 0.4769, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0391, 0.8925, 0.0373, 0.0311, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2741, 0.1508, 0.3187, 0.0735, 0.1830, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1004, 0.1210, 0.2156, 0.1775, 0.0312, 0.3543, 0.0000, 0.0000],\n",
       "         [0.0443, 0.2066, 0.1084, 0.3758, 0.0536, 0.0799, 0.1313, 0.0000],\n",
       "         [0.0200, 0.2559, 0.0680, 0.0458, 0.2710, 0.1009, 0.1908, 0.0477]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0632, 0.9368, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.7136, 0.2708, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2481, 0.0882, 0.0241, 0.6396, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0769, 0.1994, 0.4409, 0.1833, 0.0995, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0173, 0.0759, 0.0208, 0.0158, 0.8670, 0.0032, 0.0000, 0.0000],\n",
       "         [0.0456, 0.0523, 0.2264, 0.4435, 0.0696, 0.1448, 0.0177, 0.0000],\n",
       "         [0.0057, 0.0034, 0.0820, 0.0426, 0.1468, 0.0035, 0.6895, 0.0264]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.7833, 0.2167, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3109, 0.5689, 0.1202, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0123, 0.0104, 0.8971, 0.0802, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0905, 0.0841, 0.7290, 0.0209, 0.0754, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0010, 0.0090, 0.8687, 0.0175, 0.0924, 0.0112, 0.0000, 0.0000],\n",
       "         [0.0135, 0.0167, 0.5226, 0.0428, 0.0709, 0.3274, 0.0061, 0.0000],\n",
       "         [0.1195, 0.1146, 0.0160, 0.1761, 0.0482, 0.4344, 0.0049, 0.0864]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1954, 0.8046, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2980, 0.5098, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0561, 0.0127, 0.9205, 0.0108, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1647, 0.0034, 0.2656, 0.3467, 0.2196, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1275, 0.5776, 0.1756, 0.0438, 0.0059, 0.0697, 0.0000, 0.0000],\n",
       "         [0.0126, 0.2475, 0.1870, 0.0218, 0.4275, 0.0342, 0.0693, 0.0000],\n",
       "         [0.2457, 0.4614, 0.0511, 0.0638, 0.0274, 0.0067, 0.0505, 0.0934]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x)   # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "v = value(x) # (B, T, head_size)\n",
    "weights = q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) -> (B, T, T) explanation: basically, for each batch, we multiply a (T, head_size) matrix by a (head_size, T) matrix, which results in a (T, T) matrix for each batch, so we get a (B, T, T) matrix\n",
    "weights = weights / math.sqrt(head_size) # scale down the weights to prevent them from blowing up\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = weights.masked_fill(tril == 0, float(\"-inf\")) # piece de resistance of ye olde 'decoder' transformer (AR)\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "out = weights @ v\n",
    "\n",
    "out.shape # (4, 8, 32)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
